{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0015493d-3c46-4f7d-a3d2-65b315edf631",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications. There are many different ways to perform web scraping to obtain data from websites. These include using online services, particular API’s or even creating your code for web scraping from scratch. Many large websites, like Google, Twitter, Facebook, StackOverflow, etc. have API’s that allow you to access their data in a structured format. This is the best option, but there are other sites that don’t allow users to access large amounts of data in a structured form or they are simply not that technologically advanced. In that situation, it’s best to use Web Scraping to scrape the website for data.\n",
    "Web Scraping has multiple applications across various industries. Let’s check out some of these now!\n",
    "1. Price Monitoring\n",
    "Web Scraping can be used by companies to scrap the product data for their products and competing products as well to see how it impacts their pricing strategies. Companies can use this data to fix the optimal pricing for their products so that they can obtain maximum revenue.\n",
    "2. Market Research\n",
    "Web scraping can be used for market research by companies. High-quality web scraped data obtained in large volumes can be very helpful for companies in analyzing consumer trends and understanding which direction the company should move in the future. \n",
    "3. News Monitoring\n",
    "Web scraping news sites can provide detailed reports on the current news to a company. This is even more essential for companies that are frequently in the news or that depend on daily news for their day-to-day functioning. After all, news reports can make or break a company in a single day!\n",
    "4. Sentiment Analysis\n",
    "If companies want to understand the general sentiment for their products among their consumers, then Sentiment Analysis is a must. Companies can use web scraping to collect data from social media websites such as Facebook and Twitter as to what the general sentiment about their products is. This will help them in creating products that people desire and moving ahead of their competition.\n",
    "5. Email Marketing\n",
    "Companies can also use Web scraping for email marketing. They can collect Email ID’s from various sites using web scraping and then send bulk promotional and marketing Emails to all the people owning these Email ID’s.\n",
    "\n",
    "\n",
    "Q2. What are the different methods used for Web Scraping?\n",
    "\n",
    "Data Scraping Techniques\n",
    "Here are a few techniques commonly used to scrape data from websites. In general, all web scraping techniques retrieve content from websites, process it using a scraping engine, and generate one or more data files with the extracted content.\n",
    "HTML Parsing\n",
    "HTML parsing involves the use of JavaScript to target a linear or nested HTML page. It is a powerful and fast method for extracting text and links (e.g. a nested link or email address), scraping screens and pulling resources.\n",
    "DOM Parsing\n",
    "The Document Object Model (DOM) defines the structure, style and content of an XML file. Scrapers typically use a DOM parser to view the structure of web pages in depth. DOM parsers can be used to access the nodes that contain information and scrape the web page with tools like XPath. For dynamically generated content, scrapers can embed web browsers like Firefox and Internet Explorer to extract whole web pages (or parts of them).\n",
    "Vertical Aggregation\n",
    "Companies that use extensive computing power can create vertical aggregation platforms to target particular verticals. These are data harvesting platforms that can be run on the cloud and are used to automatically generate and monitor bots for certain verticals with minimal human intervention. Bots are generated according to the information required to each vertical, and their efficiency is determined by the quality of data they extract.\n",
    "XPath\n",
    "XPath is short for XML Path Language, which is a query language for XML documents. XML documents have tree-like structures, so scrapers can use XPath to navigate through them by selecting nodes according to various parameters. A scraper may combine DOM parsing with XPath to extract whole web pages and publish them on a destination site.\n",
    "Google Sheets\n",
    "Google Sheets is a popular tool for data scraping. Scarpers can use the IMPORTXML function in Sheets to scrape from a website, which is useful if they want to extract a specific pattern or data from the website. This command also makes it possible to check if a website can be scraped or is protected.\n",
    "\n",
    "\n",
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "\n",
    "Beautiful Soup\n",
    "Beautiful Soup is a Python library that makes it easy to scrape information from web pages. It sits atop an HTML or XML parser and provides Pythonic idioms for iterating, searching, and modifying the parse tree.\n",
    "Uses of Beautiful Soup\n",
    "The Beautiful Soup library helps with isolating titles and links from webpages. It can extract all of the text from HTML tags, and alter the HTML in the document with which we’re working.\n",
    "Features of Beautiful Soup\n",
    "Some key features that make beautiful soup unique are:\n",
    "•\tBeautiful Soup provides a few simple methods and Pythonic idioms for navigating, searching, and modifying a parse tree.\n",
    "•\tBeautiful Soup automatically converts incoming documents to Unicode and outgoing documents to UTF-8.\n",
    "•\tBeautiful Soup sits on top of popular Python parsers like lxml and html5lib, which allows us to try out different parsing strategies or trade speed for flexibility\n",
    "\n",
    "\n",
    "\n",
    "Q4. Why is flask used in this Web Scraping project?\n",
    "\n",
    "Flask is an API of Python that allows us to build web applications. It was developed by Armin Ronacher. Flask’s framework is more explicit than Django’s framework and is also easier to learn because it has less base code to implement a simple web application. Flask Python is based on the WSGI(Web Server Gateway Interface) toolkit and Jinja2 template engine.\n",
    "Advantages of Flask\n",
    "1.\t Flask is a lightweight backend framework with minimal dependencies.\n",
    "2.\t Flask is easy to learn because its simple and intuitive API makes it easy to learn and use for beginners.\n",
    "3.\t Flask is a flexible Framework because it allows you to customize and extend the framework to suit your needs easily.\n",
    "4.\t Flask can be used with any database like:- SQL and NoSQL and with any Frontend Technology such as React or Angular.\n",
    "5.\tFlask is great for small to medium projects that do not require the complexity of a large framework.\n",
    "6.\tFlask Documentation\n",
    "\n",
    "\n",
    "\n",
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\n",
    "REST and SOAP service used in this project.\n",
    "SOAP APIs also provide these other advantages when compared to REST APIs:\n",
    "•\tSOAP is language, transport, and even platform independent, whereas REST requires the use of HTTP.\n",
    "•\tSOAP is very secure, which makes it perfect for systems that handle sensitive data, such as financial services and online banking applications.\n",
    "•\tSOAP works well in distributed enterprise environments, instead of depending on direct point-to-point communication.\n",
    "•\tSOAP has built-in error handling features, which makes it easy to understand what happened when a request fails.\n",
    "The benefits of using REST APIs\n",
    "REST is preferable to SOAP for several reasons. Here are a few advantages that REST APIs have:\n",
    "•\tScalability: Due to the separation between client and server, the product can be scaled by development teams without much difficulty.\n",
    "•\tFlexibility and Portability: Since REST-style APIs require data from one of the requests to be sent properly, it’s possible to perform a migration from one server to another. It’s also possible to carry out changes on the database at any time.\n",
    "•\tIndependence: With the separation between client and server, the protocol makes it easier for developments across a project to take place independently. REST APIs are also adaptable to the working syntax and platform, which offers opportunities to test several environments at a time while developing.\n",
    "•\tLightweight: REST APIs are lightweight and fast, as they utilize the HTTP standard that supports multiple formats including JSON, XML, and HTML. This feature makes it ideal for mobile app projects, IoT devices, and much more.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
